{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import glob\n",
    "import itertools\n",
    "\n",
    "from IPython.display import Image\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.mlab as mlab\n",
    "from matplotlib.colors import ListedColormap\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mondrian Processes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Various Functions for Mondrian Processes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualization..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "### VISUALIZE 2D MONDRIAN PROCESS ###\n",
    "def print_partitions(p, trans_level=1., color='k'):\n",
    "    if not p[1] and not p[2]: \n",
    "        plt.plot([p[0][0,0], p[0][0,0]], [p[0][1,0], p[0][1,1]], color+'-', linewidth=5, alpha=trans_level)\n",
    "        plt.plot([p[0][0,1], p[0][0,1]], [p[0][1,0], p[0][1,1]], color+'-', linewidth=5, alpha=trans_level)\n",
    "        plt.plot([p[0][0,0], p[0][0,1]], [p[0][1,0], p[0][1,0]], color+'-', linewidth=5, alpha=trans_level)\n",
    "        plt.plot([p[0][0,0], p[0][0,1]], [p[0][1,1], p[0][1,1]], color+'-', linewidth=5, alpha=trans_level)\n",
    "    \n",
    "    else:\n",
    "        print_partitions(p[1], trans_level, color)\n",
    "        print_partitions(p[2], trans_level, color)\n",
    "        \n",
    "        \n",
    "### VISUALIZE 2D POSTERIOR WITH DATA###\n",
    "def print_posterior(data, samples, trans_level=.05, color='k'):\n",
    "\n",
    "    plt.figure()\n",
    "    plt.scatter(data[:,0], data[:,1], c='k', edgecolors='k', s=80, alpha=.5)\n",
    "\n",
    "    #print all samples\n",
    "    for sample in samples:\n",
    "        print_partitions(sample, trans_level, color)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Flow Cytometry Data\n",
    "\n",
    "Load AML dataset from [ACDC paper](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5447237/pdf/btx054.pdf)..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                        CD45RA  CD133  CD19  CD22  CD11b  CD4  CD8  CD34  \\\n",
      "Basophils                  0.0    0.0    -1   0.0    0.0  0.0 -1.0    -1   \n",
      "CD4 T cells                0.0    0.0    -1   0.0    0.0  1.0 -1.0    -1   \n",
      "CD8 T cells                0.0    0.0    -1   0.0    0.0 -1.0  1.0    -1   \n",
      "CD16- NK cells             0.0    0.0    -1   0.0    0.0  0.0  0.0    -1   \n",
      "CD16+ NK cells             0.0    0.0    -1   0.0    0.0  0.0  0.0    -1   \n",
      "CD34+CD38+CD123- HSPCs     0.0    0.0    -1   0.0    0.0  0.0 -1.0     1   \n",
      "CD34+CD38+CD123+ HSPCs     0.0    0.0    -1   0.0    0.0  0.0 -1.0     1   \n",
      "CD34+CD38lo HSCs           0.0    0.0    -1   0.0    0.0  0.0 -1.0     1   \n",
      "Mature B cells             0.0    0.0     1   0.0    0.0  0.0 -1.0    -1   \n",
      "Plasma B cells             0.0    0.0     1   0.0    0.0  0.0 -1.0    -1   \n",
      "Pre B cells                0.0    0.0     1   0.0    0.0  0.0 -1.0    -1   \n",
      "Pro B cells                0.0    0.0     1   0.0    0.0  0.0 -1.0     1   \n",
      "Monocytes                  0.0    0.0    -1   0.0    0.0  0.0 -1.0    -1   \n",
      "pDCs                       0.0    0.0    -1   0.0    0.0  0.0 -1.0    -1   \n",
      "\n",
      "                        Flt3  CD20  ...   CD44  CD38  CD13  CD3  CD61  CD117  \\\n",
      "Basophils                0.0  -1.0  ...    0.0   0.0   0.0   -1   0.0    0.0   \n",
      "CD4 T cells              0.0  -1.0  ...    0.0   0.0   0.0    1   0.0    0.0   \n",
      "CD8 T cells              0.0  -1.0  ...    0.0   0.0   0.0    1   0.0    0.0   \n",
      "CD16- NK cells           0.0  -1.0  ...    0.0   0.0   0.0   -1   0.0    0.0   \n",
      "CD16+ NK cells           0.0   0.0  ...    0.0   0.0   0.0   -1   0.0    0.0   \n",
      "CD34+CD38+CD123- HSPCs   0.0  -1.0  ...    0.0   1.0   0.0   -1   0.0    0.0   \n",
      "CD34+CD38+CD123+ HSPCs   0.0  -1.0  ...    0.0   1.0   0.0   -1   0.0    0.0   \n",
      "CD34+CD38lo HSCs         0.0  -1.0  ...    0.0  -1.0   0.0   -1   0.0    0.0   \n",
      "Mature B cells           0.0   0.0  ...    0.0   0.0   0.0   -1   0.0    0.0   \n",
      "Plasma B cells           0.0   0.0  ...    0.0   1.0   0.0   -1   0.0    0.0   \n",
      "Pre B cells              0.0   0.0  ...    0.0   1.0   0.0   -1   0.0    0.0   \n",
      "Pro B cells              0.0   0.0  ...    0.0   1.0   0.0   -1   0.0    0.0   \n",
      "Monocytes                0.0  -1.0  ...    0.0   0.0   0.0   -1   0.0    0.0   \n",
      "pDCs                     0.0  -1.0  ...    0.0   0.0   0.0   -1   0.0    0.0   \n",
      "\n",
      "                        CD49d  HLA-DR  CD64  CD41  \n",
      "Basophils                 0.0    -1.0  -1.0   0.0  \n",
      "CD4 T cells               0.0    -1.0  -1.0   0.0  \n",
      "CD8 T cells               0.0    -1.0  -1.0   0.0  \n",
      "CD16- NK cells            0.0    -1.0  -1.0   0.0  \n",
      "CD16+ NK cells            0.0    -1.0  -1.0   0.0  \n",
      "CD34+CD38+CD123- HSPCs    0.0     0.0  -1.0   0.0  \n",
      "CD34+CD38+CD123+ HSPCs    0.0     0.0  -1.0   0.0  \n",
      "CD34+CD38lo HSCs          0.0     0.0  -1.0   0.0  \n",
      "Mature B cells            0.0     0.0   0.0   0.0  \n",
      "Plasma B cells            0.0    -1.0   0.0   0.0  \n",
      "Pre B cells               0.0     1.0  -1.0   0.0  \n",
      "Pro B cells               0.0     0.0  -1.0   0.0  \n",
      "Monocytes                 0.0     1.0   0.0   0.0  \n",
      "pDCs                      0.0     1.0  -1.0   0.0  \n",
      "\n",
      "[14 rows x 32 columns]\n",
      "(104184, 32)\n"
     ]
    }
   ],
   "source": [
    "# load AML data and table\n",
    "##### X: np.array, flow cytometry data, arcsin transformed\n",
    "##### T: table of expert knowledge\n",
    "\n",
    "np.random.seed(1234)\n",
    "PATH = '/Users/enalisnick/Desktop/flow_cyto_data/'\n",
    "\n",
    "### LOAD DATA ###\n",
    "path = PATH + 'AML_benchmark/'\n",
    "df = pd.read_csv( path + 'AML_benchmark.csv.gz', sep=',', header = 0, compression = 'gzip', engine='python')\n",
    "table = pd.read_csv(path + 'AML_table.csv', sep=',', header=0, index_col=0)\n",
    "\n",
    "### PROCESS: discard ungated events ###\n",
    "df = df[df.cell_type != 'NotGated']\n",
    "df = df.drop(['Time', 'Cell_length','file_number', 'event_number', 'DNA1(Ir191)Di',\n",
    "              'DNA2(Ir193)Di', 'Viability(Pt195)Di', 'subject'], axis = 1)\n",
    "channels = [item[:item.find('(')] for item in df.columns[:-1]]\n",
    "df.columns = channels + ['cell_type']\n",
    "df = df.loc[df['cell_type'] != 'NotDebrisSinglets']\n",
    "\n",
    "table = table.fillna(0)\n",
    "X = df[channels].values\n",
    "table_headers = list(table)\n",
    "\n",
    "### transform data\n",
    "data = np.arcsinh((X-1.)/5.)\n",
    "\n",
    "print table\n",
    "print X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mondrian Process Generative Model\n",
    "\n",
    "We apply Mondrian Processes (MPs) to flow cytometry data, using the prior information in the table above to guide the axis-aligned cuts.  Instead of uniformly, we draw the cut proportion from $w \\sim \\text{Beta}(a_{0}, b_{0})$. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAW8AAAEACAYAAAB8nvebAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ni4gEkMpbRCSAVN4iIgH0/wFABohyR8fw8QAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11ae258d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure()\n",
    "\n",
    "a0, b0 = 5, 1\n",
    "beta_samples = np.random.beta(a0, b0, 1000)\n",
    "\n",
    "n, bins, patches = plt.hist(beta_samples,[x*10**(-2) for x in range(100)], normed=1, histtype='stepfilled')\n",
    "plt.setp(patches, 'facecolor', 'b', 'alpha', 0.75)\n",
    "\n",
    "plt.xlim([0,1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's re-implement the MP sampling function, accounting for the prior information..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def draw_informed_Mondrian_at_t(theta_space, table, priors_dict, cut_history):\n",
    "    \n",
    "    if sum(cut_history) == 0 or table.shape[0] == 1 or table.shape[0] == 0:\n",
    "        return (theta_space, None, None)\n",
    "    \n",
    "    low, medium, high = 0.01, 1, 100\n",
    "    priority_dict = {'-1': low , '0': low, '1': low, \n",
    "                   '-1 0': medium, '0 1': medium,\n",
    "                   '-1 0 1': high, '-1 1':high\n",
    "    }\n",
    "    \n",
    "    types_str = [' '.join([str(int(x)) for x in sorted(set(table[table.columns[d]]))]) for d in range(table.shape[1])]\n",
    "    if set([types_str[d] for d in range(table.shape[1]) if cut_history[d] == 1]).issubset({'0','1','-1'}):\n",
    "        return (theta_space, None, None)\n",
    "    \n",
    "    types = np.array([priority_dict[_] for _ in types_str])\n",
    "    \n",
    "\n",
    "    dists = (theta_space[:,1] - theta_space[:,0])* types    \n",
    "    lin_dim = np.sum(dists)\n",
    "    \n",
    "    \n",
    "    # draw dimension to cut\n",
    "    dim_probs = ((dists/lin_dim) * np.array(cut_history)) \n",
    "    dim_probs /= np.sum(dim_probs)\n",
    "    d = np.argmax(np.random.multinomial(n=1, pvals=dim_probs))\n",
    "    #print \"make a cut at dim: %d \" % d\n",
    "    cut_history[d] = 0\n",
    "\n",
    "    prior_type_str = ' '.join([str(int(x)) for x in sorted(set(table[table.columns[d]]))])\n",
    "    prior_params = priors_dict[prior_type_str]\n",
    "    \n",
    "    # make scaled cut\n",
    "    x = (theta_space[d,1] - theta_space[d,0]) * np.random.beta(prior_params[0], prior_params[1]) + theta_space[d,0]\n",
    "    \n",
    "    idx_table_left = table[table.columns[d]] != 1\n",
    "    table_left = table.loc[idx_table_left]\n",
    "\n",
    "    idx_table_right = table[table.columns[d]] != -1\n",
    "    table_right = table.loc[idx_table_right]\n",
    "    \n",
    "    # make lower partition\n",
    "    theta_left = np.copy(theta_space)\n",
    "    theta_left[d][1] = x\n",
    "    M_left = draw_informed_Mondrian_at_t(theta_left, table_left, priors_dict, list(cut_history))\n",
    "    \n",
    "    # make upper partition\n",
    "    theta_right = np.copy(theta_space)\n",
    "    theta_right[d][0] = x \n",
    "    M_right = draw_informed_Mondrian_at_t(theta_right, table_right, priors_dict,list(cut_history))\n",
    "    \n",
    "    return (theta_space, M_left, M_right)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "### SAMPLE MONDRIAN PROCESS WITH PRIOR INFORMATION ###\n",
    "def draw_informed_Mondrian(theta_space, table, budget=5):\n",
    "    \n",
    "    # INFORMATIVE PRIORS\n",
    "    upper_cut = (5., 1.)\n",
    "    lower_cut = (1., 5.)\n",
    "    middle_cut = (5., 5.)\n",
    "    neutral_cut = (1., 1.)\n",
    "    priors_dict = { '-1':lower_cut, '0':neutral_cut, '1':upper_cut, \n",
    "                   '-1 0':lower_cut, '-1 1':middle_cut, '0 1':upper_cut,\n",
    "                   '-1 0 1': middle_cut, '': neutral_cut\n",
    "                  }\n",
    "    \n",
    "    # init dimension mask\n",
    "    dim_mask = np.ones((theta_space.shape[0],))\n",
    "    \n",
    "    # get dims with prior info\n",
    "    for d in range(dim_mask.shape[0]):\n",
    "        matching_prior_info = sorted(set(table[table.columns[d]]))\n",
    "        s = ' '.join([str(int(x)) for x in matching_prior_info])\n",
    "        if s == '0' or s=='-1' or s=='1': #or s=='-1 0' or s=='0 1' or s=='-1' or s=='1'\n",
    "            dim_mask[d] = 0. \n",
    "            \n",
    "    #print np.sum(dim_mask)\n",
    "    \n",
    "    return draw_informed_Mondrian_at_t(theta_space, table, priors_dict, dim_mask)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment #1: Subset of Data, All Dimensions\n",
    "\n",
    "Let's now test out the idea on (a subset of) the data with all dimensions.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5000 32\n",
      "Index([u'CD45RA', u'CD133', u'CD19', u'CD22', u'CD11b', u'CD4', u'CD8',\n",
      "       u'CD34', u'Flt3', u'CD20', u'CXCR4', u'CD235ab', u'CD45', u'CD123',\n",
      "       u'CD321', u'CD14', u'CD33', u'CD47', u'CD11c', u'CD7', u'CD15', u'CD16',\n",
      "       u'CD44', u'CD38', u'CD13', u'CD3', u'CD61', u'CD117', u'CD49d',\n",
      "       u'HLADR', u'CD64', u'CD41'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "np.random.shuffle(data)\n",
    "data_5k = data[:5000,:]\n",
    "N, d = data_5k.shape\n",
    "print N,d\n",
    "\n",
    "# rename table header 'HLA-DR' to 'HLADR' to prevent error from '-'\n",
    "temp_headers = list(table)\n",
    "temp_headers[29] = \"HLADR\"\n",
    "table.columns = temp_headers\n",
    "print table.columns\n",
    "\n",
    "'''\n",
    "### FOR TESTING\n",
    "data_5k = np.hstack([data[:,5][np.newaxis].T, data[:,6][np.newaxis].T])\n",
    "np.random.shuffle(data_5k)\n",
    "data_5k = data_5k[:5000,:]\n",
    "table = table[['CD4', 'CD8']]\n",
    "N, d = data_5k.shape\n",
    "'''\n",
    "\n",
    "emp_bounds = [(data_5k[:,i].min(), data_5k[:,i].max()) for i in range(d)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Approximate MLE\n",
    "\n",
    "Let's first calculate an approximate MLE using K-Means.  This will be used to assess MCMC burn in..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log prob. MLE: -106992.234222\n"
     ]
    }
   ],
   "source": [
    "mle_K = 20\n",
    "\n",
    "# run K means (instead of medians)\n",
    "kmeans = KMeans(n_clusters=mle_K, max_iter=1000, n_jobs=1)\n",
    "mle_cluster_assignments = kmeans.fit_predict(data_5k)\n",
    "\n",
    "# get each cluster's bounds\n",
    "mle_cluster_bounds = get_cluster_bounds(data_5k, mle_cluster_assignments)\n",
    "\n",
    "#Calculate max. likelihood estimate\n",
    "log_p_MLE = 0.\n",
    "for k_idx in range(mle_K):\n",
    "    k_count = len(np.nonzero(mle_cluster_assignments==k_idx)[0])\n",
    "    log_p_MLE += k_count * np.sum( [-np.log(mle_cluster_bounds[k_idx][i][1]-mle_cluster_bounds[k_idx][i][0]) for i in range(d)] )\n",
    "    \n",
    "print \"log prob. MLE: %f\" %(log_p_MLE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Posterior Inference with MCMC\n",
    "\n",
    "Now run MCMC to collect posterior samples.  First let's define a cut proposal function..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def Mondrian_Gaussian_perturbation(theta_space, old_sample, stepsize=.5):\n",
    "    \"\"\"\n",
    "    Input: \n",
    "    theta_space: a rectangle\n",
    "    old_sample: partioned theta_space of a mondrian process\n",
    "    stepsize: gaussian std\n",
    "    \"\"\"\n",
    "    if old_sample[1] == None and old_sample[2] == None:\n",
    "        return (theta_space, None, None)\n",
    "    \n",
    "    # find the dimension and location of first cut in the old_sample\n",
    "    for _ in range(old_sample[0].shape[0]):\n",
    "        if old_sample[0][_,1] > old_sample[1][0][_,1]:\n",
    "            break    \n",
    "    dim, pos = _, old_sample[1][0][_,1]\n",
    "    # propose position of new cut\n",
    "    good_propose = False\n",
    "    while good_propose == False:\n",
    "        new_pos = pos + np.random.normal(0,(old_sample[0][dim,1] - old_sample[0][dim,0])*stepsize,1)[0]\n",
    "        if new_pos < theta_space[dim,1] and new_pos > theta_space[dim,0]:\n",
    "            good_propose = True\n",
    "    \n",
    "    theta_left = np.copy(theta_space)\n",
    "    theta_left[dim,1] = new_pos\n",
    "    theta_right = np.copy(theta_space)\n",
    "    theta_right[dim,0] = new_pos\n",
    "    \n",
    "    new_M_left= Mondrian_Gaussian_perturbation(theta_left, old_sample[1], stepsize)\n",
    "    new_M_right = Mondrian_Gaussian_perturbation(theta_right, old_sample[2], stepsize)\n",
    "    \n",
    "    return (theta_space, new_M_left, new_M_right)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's declare a function for log likelihood calculations..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def comp_log_p_sample(theta_space, data):\n",
    "    if theta_space[1] == None and theta_space[2] == None:\n",
    "        return 0\n",
    "    \n",
    "    # find the dimension and location of first cut\n",
    "    root_rec = theta_space[0]\n",
    "    left_rec = theta_space[1][0]\n",
    "    \n",
    "    for _ in range(root_rec.shape[0]):\n",
    "        if root_rec[_,1] != left_rec[_,1]:\n",
    "            break\n",
    "    \n",
    "    dim, pos = _, left_rec[_,1]\n",
    "    idx_left = data[:,dim] < pos\n",
    "    idx_right = data[:,dim] >= pos\n",
    "    log_len_left =  np.log(pos - root_rec[dim,0])\n",
    "    log_len_right = np.log(root_rec[dim,1] - pos)\n",
    "    return - idx_left.sum() * log_len_left - idx_right.sum() * log_len_right +\\\n",
    "            comp_log_p_sample(theta_space[1], data[idx_left]) + comp_log_p_sample(theta_space[2], data[idx_right])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, let's run our MCMC iterations..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running chain #0...\n",
      "Iteration 250, Samples 17, Avg time per iter. 0.0116, log p of current sample -14046.83\n",
      "Iteration 500, Samples 19, Avg time per iter. 0.0116, log p of current sample -12126.80\n",
      "Iteration 750, Samples 19, Avg time per iter. 0.0102, log p of current sample -12126.80\n",
      "Iteration 1000, Samples 20, Avg time per iter. 0.0105, log p of current sample -12093.30\n",
      "Iteration 1250, Samples 21, Avg time per iter. 0.0108, log p of current sample -11504.23\n",
      "Iteration 1500, Samples 21, Avg time per iter. 0.0113, log p of current sample -11504.23\n",
      "Iteration 1750, Samples 21, Avg time per iter. 0.0116, log p of current sample -11504.23\n",
      "Iteration 2000, Samples 22, Avg time per iter. 0.0108, log p of current sample -11425.52\n",
      "Iteration 2250, Samples 23, Avg time per iter. 0.0110, log p of current sample -11352.58\n",
      "Iteration 2500, Samples 24, Avg time per iter. 0.0107, log p of current sample -10149.97\n",
      "Iteration 2750, Samples 24, Avg time per iter. 0.0116, log p of current sample -10149.97\n",
      "Iteration 3000, Samples 24, Avg time per iter. 0.0113, log p of current sample -10149.97\n",
      "Iteration 3250, Samples 24, Avg time per iter. 0.0107, log p of current sample -10149.97\n",
      "Iteration 3500, Samples 24, Avg time per iter. 0.0110, log p of current sample -10149.97\n",
      "Iteration 3750, Samples 24, Avg time per iter. 0.0110, log p of current sample -10149.97\n",
      "Iteration 4000, Samples 24, Avg time per iter. 0.0109, log p of current sample -10149.97\n",
      "Iteration 4250, Samples 24, Avg time per iter. 0.0113, log p of current sample -10149.97\n",
      "Iteration 4500, Samples 24, Avg time per iter. 0.0110, log p of current sample -10149.97\n",
      "Iteration 4750, Samples 24, Avg time per iter. 0.0114, log p of current sample -10149.97\n",
      "Iteration 5000, Samples 24, Avg time per iter. 0.0113, log p of current sample -10149.97\n",
      "Iteration 5250, Samples 24, Avg time per iter. 0.0112, log p of current sample -10149.97\n",
      "Iteration 5500, Samples 24, Avg time per iter. 0.0109, log p of current sample -10149.97\n",
      "Iteration 5750, Samples 24, Avg time per iter. 0.0116, log p of current sample -10149.97\n",
      "Iteration 6000, Samples 24, Avg time per iter. 0.0117, log p of current sample -10149.97\n",
      "Iteration 6250, Samples 24, Avg time per iter. 0.0115, log p of current sample -10149.97\n",
      "Iteration 6500, Samples 24, Avg time per iter. 0.0121, log p of current sample -10149.97\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import sys\n",
    "\n",
    "def get_Mondrian_partition_bounds(p):\n",
    "    if not p[1] and not p[2]: \n",
    "        return [[(p[0][i,0], p[0][i,1]) for i in range(d)]]\n",
    "    else:\n",
    "        return get_Mondrian_partition_bounds(p[1]) + get_Mondrian_partition_bounds(p[2])\n",
    "\n",
    "    \n",
    "n_chains = 10\n",
    "n_its_per_chain = 10000\n",
    "burn_in_threshold = log_p_MLE - 10000\n",
    "\n",
    "samples = []\n",
    "time_agg = 0.\n",
    "for chain_idx in xrange(n_chains):\n",
    "    \n",
    "    print \"Running chain #%d...\" %(chain_idx)\n",
    "    \n",
    "    # get inital starting sample\n",
    "    sample = draw_informed_Mondrian(np.array(emp_bounds), table, budget=1.)\n",
    "    log_p_sample = comp_log_p_sample(sample, data_5k) \n",
    "    \n",
    "    for idx in xrange(n_its_per_chain):    \n",
    "        start = time.time()\n",
    "        \n",
    "        new_sample = Mondrian_Gaussian_perturbation(theta_space=np.array(emp_bounds), old_sample=sample, stepsize=.1)\n",
    "        log_p_new_sample = comp_log_p_sample(new_sample, data_5k) \n",
    "        \n",
    "        # perform accept-reject step\n",
    "        if log_p_sample <= log_p_new_sample and np.log(np.random.uniform(low=0, high=1.)) < log_p_new_sample - log_p_sample:\n",
    "            \n",
    "            # check if we've burned in or not\n",
    "            if log_p_new_sample > burn_in_threshold:\n",
    "                samples.append(sample)\n",
    "            \n",
    "            sample = new_sample\n",
    "            log_p_sample = log_p_new_sample\n",
    "    \n",
    "        end = time.time()\n",
    "        time_agg += (end-start)\n",
    "        \n",
    "        if (idx+1) % 250 == 0:\n",
    "            print \"Iteration %d, Samples %d, Avg time per iter. %.4f, log p of current sample %.2f\" %(idx+1, len(samples), time_agg/100, log_p_sample)\n",
    "            time_agg = 0.\n",
    "\n",
    "print \"Number of samples collected: %d\" %(len(samples))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute Classification Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
