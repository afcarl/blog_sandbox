{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import glob\n",
    "import itertools\n",
    "\n",
    "from IPython.display import Image\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.mlab as mlab\n",
    "from matplotlib.colors import ListedColormap\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mondrian Processes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Various Functions for Mondrian Processes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualization..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "### VISUALIZE 2D MONDRIAN PROCESS ###\n",
    "def print_partitions(p, trans_level=1., color='k'):\n",
    "    if not p[1] and not p[2]: \n",
    "        plt.plot([p[0][0,0], p[0][0,0]], [p[0][1,0], p[0][1,1]], color+'-', linewidth=5, alpha=trans_level)\n",
    "        plt.plot([p[0][0,1], p[0][0,1]], [p[0][1,0], p[0][1,1]], color+'-', linewidth=5, alpha=trans_level)\n",
    "        plt.plot([p[0][0,0], p[0][0,1]], [p[0][1,0], p[0][1,0]], color+'-', linewidth=5, alpha=trans_level)\n",
    "        plt.plot([p[0][0,0], p[0][0,1]], [p[0][1,1], p[0][1,1]], color+'-', linewidth=5, alpha=trans_level)\n",
    "    \n",
    "    else:\n",
    "        print_partitions(p[1], trans_level, color)\n",
    "        print_partitions(p[2], trans_level, color)\n",
    "        \n",
    "        \n",
    "### VISUALIZE 2D POSTERIOR WITH DATA###\n",
    "def print_posterior(data, samples, trans_level=.05, color='k'):\n",
    "\n",
    "    plt.figure()\n",
    "    plt.scatter(data[:,0], data[:,1], c='k', edgecolors='k', s=80, alpha=.5)\n",
    "\n",
    "    #print all samples\n",
    "    for sample in samples:\n",
    "        print_partitions(sample, trans_level, color)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Flow Cytometry Data\n",
    "\n",
    "Load AML dataset from [ACDC paper](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5447237/pdf/btx054.pdf)..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# load AML data and table\n",
    "##### X: np.array, flow cytometry data, arcsin transformed\n",
    "##### T: table of expert knowledge\n",
    "\n",
    "np.random.seed(1234)\n",
    "PATH = '/Users/enalisnick/Desktop/flow_cyto_data/'\n",
    "\n",
    "### LOAD DATA ###\n",
    "path = PATH + 'AML_benchmark/'\n",
    "df = pd.read_csv( path + 'AML_benchmark.csv.gz', sep=',', header = 0, compression = 'gzip', engine='python')\n",
    "table = pd.read_csv(path + 'AML_table.csv', sep=',', header=0, index_col=0)\n",
    "\n",
    "### PROCESS: discard ungated events ###\n",
    "df = df[df.cell_type != 'NotGated']\n",
    "df = df.drop(['Time', 'Cell_length','file_number', 'event_number', 'DNA1(Ir191)Di',\n",
    "              'DNA2(Ir193)Di', 'Viability(Pt195)Di', 'subject'], axis = 1)\n",
    "channels = [item[:item.find('(')] for item in df.columns[:-1]]\n",
    "df.columns = channels + ['cell_type']\n",
    "df = df.loc[df['cell_type'] != 'NotDebrisSinglets']\n",
    "\n",
    "table = table.fillna(0)\n",
    "X = df[channels].values\n",
    "table_headers = list(table)\n",
    "\n",
    "### transform data\n",
    "data = np.arcsinh((X-1.)/5.)\n",
    "\n",
    "print table\n",
    "print X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mondrian Process Generative Model\n",
    "\n",
    "We apply Mondrian Processes (MPs) to flow cytometry data, using the prior information in the table above to guide the axis-aligned cuts.  Instead of uniformly, we draw the cut proportion from $w \\sim \\text{Beta}(a_{0}, b_{0})$. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "\n",
    "a0, b0 = 5, 1\n",
    "beta_samples = np.random.beta(a0, b0, 1000)\n",
    "\n",
    "n, bins, patches = plt.hist(beta_samples,[x*10**(-2) for x in range(100)], normed=1, histtype='stepfilled')\n",
    "plt.setp(patches, 'facecolor', 'b', 'alpha', 0.75)\n",
    "\n",
    "plt.xlim([0,1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's re-implement the MP sampling function, accounting for the prior information..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def draw_informed_Mondrian_at_t(theta_space, table, priors_dict, cut_history):\n",
    "    \n",
    "    if sum(cut_history) == 0 or table.shape[0] == 1 or table.shape[0] == 0:\n",
    "        return (theta_space, None, None)\n",
    "    \n",
    "    low, medium, high = 0.01, 1, 100\n",
    "    priority_dict = {'-1': low , '0': low, '1': low, \n",
    "                   '-1 0': medium, '0 1': medium,\n",
    "                   '-1 0 1': high, '-1 1':high\n",
    "    }\n",
    "    \n",
    "    types_str = [' '.join([str(int(x)) for x in sorted(set(table[table.columns[d]]))]) for d in range(table.shape[1])]\n",
    "    if set([types_str[d] for d in range(table.shape[1]) if cut_history[d] == 1]).issubset({'0','1','-1'}):\n",
    "        return (theta_space, None, None)\n",
    "    \n",
    "    types = np.array([priority_dict[_] for _ in types_str])\n",
    "    \n",
    "\n",
    "    dists = (theta_space[:,1] - theta_space[:,0])* types    \n",
    "    lin_dim = np.sum(dists)\n",
    "    \n",
    "    \n",
    "    # draw dimension to cut\n",
    "    dim_probs = ((dists/lin_dim) * np.array(cut_history)) \n",
    "    dim_probs /= np.sum(dim_probs)\n",
    "    d = np.argmax(np.random.multinomial(n=1, pvals=dim_probs))\n",
    "    #print \"make a cut at dim: %d \" % d\n",
    "    cut_history[d] = 0\n",
    "\n",
    "    prior_type_str = ' '.join([str(int(x)) for x in sorted(set(table[table.columns[d]]))])\n",
    "    prior_params = priors_dict[prior_type_str]\n",
    "    \n",
    "    # make scaled cut\n",
    "    x = (theta_space[d,1] - theta_space[d,0]) * np.random.beta(prior_params[0], prior_params[1]) + theta_space[d,0]\n",
    "    \n",
    "    idx_table_left = table[table.columns[d]] != 1\n",
    "    table_left = table.loc[idx_table_left]\n",
    "\n",
    "    idx_table_right = table[table.columns[d]] != -1\n",
    "    table_right = table.loc[idx_table_right]\n",
    "    \n",
    "    # make lower partition\n",
    "    theta_left = np.copy(theta_space)\n",
    "    theta_left[d][1] = x\n",
    "    M_left = draw_informed_Mondrian_at_t(theta_left, table_left, priors_dict, list(cut_history))\n",
    "    \n",
    "    # make upper partition\n",
    "    theta_right = np.copy(theta_space)\n",
    "    theta_right[d][0] = x \n",
    "    M_right = draw_informed_Mondrian_at_t(theta_right, table_right, priors_dict,list(cut_history))\n",
    "    \n",
    "    return (theta_space, M_left, M_right)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "### SAMPLE MONDRIAN PROCESS WITH PRIOR INFORMATION ###\n",
    "def draw_informed_Mondrian(theta_space, table, budget=5):\n",
    "    \n",
    "    # INFORMATIVE PRIORS\n",
    "    upper_cut = (5., 1.)\n",
    "    lower_cut = (1., 5.)\n",
    "    middle_cut = (5., 5.)\n",
    "    neutral_cut = (1., 1.)\n",
    "    priors_dict = { '-1':lower_cut, '0':neutral_cut, '1':upper_cut, \n",
    "                   '-1 0':lower_cut, '-1 1':middle_cut, '0 1':upper_cut,\n",
    "                   '-1 0 1': middle_cut, '': neutral_cut\n",
    "                  }\n",
    "    \n",
    "    # init dimension mask\n",
    "    dim_mask = np.ones((theta_space.shape[0],))\n",
    "    \n",
    "    # get dims with prior info\n",
    "    for d in range(dim_mask.shape[0]):\n",
    "        matching_prior_info = sorted(set(table[table.columns[d]]))\n",
    "        s = ' '.join([str(int(x)) for x in matching_prior_info])\n",
    "        if s == '0' or s=='-1' or s=='1': #or s=='-1 0' or s=='0 1' or s=='-1' or s=='1'\n",
    "            dim_mask[d] = 0. \n",
    "            \n",
    "    #print np.sum(dim_mask)\n",
    "    \n",
    "    return draw_informed_Mondrian_at_t(theta_space, table, priors_dict, dim_mask)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment #1: Subset of Data, All Dimensions\n",
    "\n",
    "Let's now test out the idea on (a subset of) the data with all dimensions.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.random.shuffle(data)\n",
    "data_5k = data[:5000,:]\n",
    "N, d = data_5k.shape\n",
    "print N,d\n",
    "\n",
    "# rename table header 'HLA-DR' to 'HLADR' to prevent error from '-'\n",
    "temp_headers = list(table)\n",
    "temp_headers[29] = \"HLADR\"\n",
    "table.columns = temp_headers\n",
    "print table.columns\n",
    "\n",
    "'''\n",
    "### FOR TESTING\n",
    "data_5k = np.hstack([data[:,5][np.newaxis].T, data[:,6][np.newaxis].T])\n",
    "np.random.shuffle(data_5k)\n",
    "data_5k = data_5k[:5000,:]\n",
    "table = table[['CD4', 'CD8']]\n",
    "N, d = data_5k.shape\n",
    "'''\n",
    "\n",
    "emp_bounds = [(data_5k[:,i].min(), data_5k[:,i].max()) for i in range(d)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Approximate MLE\n",
    "\n",
    "Let's first calculate an approximate MLE using K-Means.  This will be used to assess MCMC burn in..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mle_K = 20\n",
    "\n",
    "# run K means (instead of medians)\n",
    "kmeans = KMeans(n_clusters=mle_K, max_iter=1000, n_jobs=1)\n",
    "mle_cluster_assignments = kmeans.fit_predict(data_5k)\n",
    "\n",
    "# get each cluster's bounds\n",
    "mle_cluster_bounds = get_cluster_bounds(data_5k, mle_cluster_assignments)\n",
    "\n",
    "#Calculate max. likelihood estimate\n",
    "log_p_MLE = 0.\n",
    "for k_idx in range(mle_K):\n",
    "    k_count = len(np.nonzero(mle_cluster_assignments==k_idx)[0])\n",
    "    log_p_MLE += k_count * np.sum( [-np.log(mle_cluster_bounds[k_idx][i][1]-mle_cluster_bounds[k_idx][i][0]) for i in range(d)] )\n",
    "    \n",
    "print \"log prob. MLE: %f\" %(log_p_MLE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Posterior Inference with MCMC\n",
    "\n",
    "Now run MCMC to collect posterior samples.  First let's define a cut proposal function..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def Mondrian_Gaussian_perturbation(theta_space, old_sample, stepsize=.5):\n",
    "    \"\"\"\n",
    "    Input: \n",
    "    theta_space: a rectangle\n",
    "    old_sample: partioned theta_space of a mondrian process\n",
    "    stepsize: gaussian std\n",
    "    \"\"\"\n",
    "    if old_sample[1] == None and old_sample[2] == None:\n",
    "        return (theta_space, None, None)\n",
    "    \n",
    "    # find the dimension and location of first cut in the old_sample\n",
    "    for _ in range(old_sample[0].shape[0]):\n",
    "        if old_sample[0][_,1] > old_sample[1][0][_,1]:\n",
    "            break    \n",
    "    dim, pos = _, old_sample[1][0][_,1]\n",
    "    # propose position of new cut\n",
    "    good_propose = False\n",
    "    while good_propose == False:\n",
    "        new_pos = pos + np.random.normal(0,(old_sample[0][dim,1] - old_sample[0][dim,0])*stepsize,1)[0]\n",
    "        if new_pos < theta_space[dim,1] and new_pos > theta_space[dim,0]:\n",
    "            good_propose = True\n",
    "    \n",
    "    theta_left = np.copy(theta_space)\n",
    "    theta_left[dim,1] = new_pos\n",
    "    theta_right = np.copy(theta_space)\n",
    "    theta_right[dim,0] = new_pos\n",
    "    \n",
    "    new_M_left= Mondrian_Gaussian_perturbation(theta_left, old_sample[1], stepsize)\n",
    "    new_M_right = Mondrian_Gaussian_perturbation(theta_right, old_sample[2], stepsize)\n",
    "    \n",
    "    return (theta_space, new_M_left, new_M_right)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's declare a function for log likelihood calculations..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def comp_log_p_sample(theta_space, data):\n",
    "    if theta_space[1] == None and theta_space[2] == None:\n",
    "        return 0\n",
    "    \n",
    "    # find the dimension and location of first cut\n",
    "    root_rec = theta_space[0]\n",
    "    left_rec = theta_space[1][0]\n",
    "    \n",
    "    for _ in range(root_rec.shape[0]):\n",
    "        if root_rec[_,1] != left_rec[_,1]:\n",
    "            break\n",
    "    \n",
    "    dim, pos = _, left_rec[_,1]\n",
    "    idx_left = data[:,dim] < pos\n",
    "    idx_right = data[:,dim] >= pos\n",
    "    log_len_left =  np.log(pos - root_rec[dim,0])\n",
    "    log_len_right = np.log(root_rec[dim,1] - pos)\n",
    "    return - idx_left.sum() * log_len_left - idx_right.sum() * log_len_right +\\\n",
    "            comp_log_p_sample(theta_space[1], data[idx_left]) + comp_log_p_sample(theta_space[2], data[idx_right])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, let's run our MCMC iterations..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import sys\n",
    "\n",
    "def get_Mondrian_partition_bounds(p):\n",
    "    if not p[1] and not p[2]: \n",
    "        return [[(p[0][i,0], p[0][i,1]) for i in range(d)]]\n",
    "    else:\n",
    "        return get_Mondrian_partition_bounds(p[1]) + get_Mondrian_partition_bounds(p[2])\n",
    "\n",
    "    \n",
    "n_chains = 10\n",
    "n_its_per_chain = 10000\n",
    "burn_in_threshold = log_p_MLE - 10000\n",
    "\n",
    "samples = []\n",
    "time_agg = 0.\n",
    "for chain_idx in xrange(n_chains):\n",
    "    \n",
    "    print \"Running chain #%d...\" %(chain_idx)\n",
    "    \n",
    "    # get inital starting sample\n",
    "    sample = draw_informed_Mondrian(np.array(emp_bounds), table, budget=1.)\n",
    "    log_p_sample = comp_log_p_sample(sample, data_5k) \n",
    "    \n",
    "    for idx in xrange(n_its_per_chain):    \n",
    "        start = time.time()\n",
    "        \n",
    "        new_sample = Mondrian_Gaussian_perturbation(theta_space=np.array(emp_bounds), old_sample=sample, stepsize=.1)\n",
    "        log_p_new_sample = comp_log_p_sample(new_sample, data_5k) \n",
    "        \n",
    "        # perform accept-reject step\n",
    "        if log_p_sample <= log_p_new_sample and np.log(np.random.uniform(low=0, high=1.)) < log_p_new_sample - log_p_sample:\n",
    "            \n",
    "            # check if we've burned in or not\n",
    "            if log_p_new_sample > burn_in_threshold:\n",
    "                samples.append(sample)\n",
    "            \n",
    "            sample = new_sample\n",
    "            log_p_sample = log_p_new_sample\n",
    "    \n",
    "        end = time.time()\n",
    "        time_agg += (end-start)\n",
    "        \n",
    "        if (idx+1) % 250 == 0:\n",
    "            print \"Iteration %d, Samples %d, Avg time per iter. %.4f, log p of current sample %.2f\" %(idx+1, len(samples), time_agg/100, log_p_sample)\n",
    "            time_agg = 0.\n",
    "\n",
    "print \"Number of samples collected: %d\" %(len(samples))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute Classification Accuracy\n",
    "\n",
    "Let's make a function to classify cells based on their partition..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "def classify_cells(data, data_idxs, mp_tree, table):\n",
    "    if mp_tree[1] == None and mp_tree[2] == None:\n",
    "        labels = list(table.index)\n",
    "        data_idxs = data_idxs.tolist()\n",
    "        \n",
    "        n_cells = len(data_idxs)\n",
    "        n_labels = len(labels)\n",
    "        label_idx = 0\n",
    "        \n",
    "        if n_cells == 0: return []\n",
    "        \n",
    "        if n_labels > 1: \n",
    "            print \"Multiple labels (%d) assigned to %d cells!\" %(n_labels, n_cells)\n",
    "            print \"\\t\"+str(labels)\n",
    "            print\n",
    "            label_idx = random.randint(0, n_labels-1)\n",
    "            \n",
    "        return [[idx, label] for idx,label in zip(data_idxs, [labels[label_idx]]*n_cells)]\n",
    "    \n",
    "    \n",
    "    # find the dimension and location of first cut\n",
    "    root_rec = mp_tree[0]\n",
    "    left_rec = mp_tree[1][0]\n",
    "    \n",
    "    for _ in range(root_rec.shape[0]):\n",
    "        if root_rec[_,1] != left_rec[_,1]:\n",
    "            break\n",
    "    dim, pos = _, left_rec[_,1]\n",
    "    \n",
    "    # find labels that match dim info from table\n",
    "    idx_table_left = table[table.columns[dim]] != 1\n",
    "    table_left = table.loc[idx_table_left]\n",
    "\n",
    "    idx_table_right = table[table.columns[dim]] != -1\n",
    "    table_right = table.loc[idx_table_right]\n",
    "    \n",
    "    # find data INDICIES that go high / low on cut position in dimension dim\n",
    "    idx_left = data_idxs[data[data_idxs, dim] < pos]\n",
    "    idx_right = data_idxs[data[data_idxs, dim] >= pos]\n",
    "\n",
    "    return classify_cells(data, idx_left, mp_tree[1], table_left) + classify_cells(data, idx_right, mp_tree[2], table_right)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run on 10k test points..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 32)\n",
      "(10000,)\n",
      "Multiple labels (2) assigned to 1 cells!\n",
      "\t['Mature B cells', 'Plasma B cells']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_idxs = range(data.shape[0])\n",
    "np.random.shuffle(test_idxs)\n",
    "test_idxs = test_idxs[:10000]\n",
    "\n",
    "data_test = data[test_idxs,:]\n",
    "data_labels = df['cell_type'].values[test_idxs]\n",
    "\n",
    "print data_test.shape\n",
    "print data_labels.shape\n",
    "\n",
    "preds = classify_cells(data_test, np.array(range(data_test.shape[0])), test_sample, table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'CD34+CD38+CD123+ HSPCs': [0, 23], 'Mature B cells': [45, 1609], 'CD34+CD38lo HSCs': [1, 80], 'pDCs': [11, 129], 'Pro B cells': [0, 51], 'CD34+CD38+CD123- HSPCs': [1, 327], 'Pre B cells': [0, 610], 'CD4 T cells': [139, 2540], 'Monocytes': [711, 1970], 'Plasma B cells': [0, 30], 'Basophils': [10, 111], 'CD16+ NK cells': [32, 207], 'CD16- NK cells': [5, 358], 'CD8 T cells': [204, 1955]}\n"
     ]
    }
   ],
   "source": [
    "accuracy = {}\n",
    "for l in list(table.index):\n",
    "    accuracy[l] = [0, 0]\n",
    "\n",
    "for p in preds: \n",
    "    if p[1] == data_labels[p[0]]:\n",
    "        accuracy[p[1]][0] = accuracy[p[1]][0] + 1\n",
    "    accuracy[data_labels[p[0]]][1] = accuracy[data_labels[p[0]]][1] + 1\n",
    "    \n",
    "print accuracy"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
